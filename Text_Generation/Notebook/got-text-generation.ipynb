{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-13T17:04:37.085427Z","iopub.execute_input":"2022-11-13T17:04:37.086244Z","iopub.status.idle":"2022-11-13T17:04:37.118560Z","shell.execute_reply.started":"2022-11-13T17:04:37.086146Z","shell.execute_reply":"2022-11-13T17:04:37.117623Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/text-corpus/text_corpus.txt\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow.keras\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential \nfrom tensorflow.keras.layers import LSTM,Dense,Flatten,Embedding\nfrom keras.preprocessing.sequence import pad_sequences\nimport re\nfrom nltk.corpus import stopwords\nimport string\n\nimport joblib","metadata":{"execution":{"iopub.status.busy":"2022-11-13T17:04:37.120039Z","iopub.execute_input":"2022-11-13T17:04:37.120769Z","iopub.status.idle":"2022-11-13T17:04:44.862393Z","shell.execute_reply.started":"2022-11-13T17:04:37.120716Z","shell.execute_reply":"2022-11-13T17:04:44.861065Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"file=open(\"../input/text-corpus/text_corpus.txt\",'r')\ntext=file.read()\nfile.close()\nprint(text[0:100])","metadata":{"execution":{"iopub.status.busy":"2022-11-13T17:04:44.864258Z","iopub.execute_input":"2022-11-13T17:04:44.865131Z","iopub.status.idle":"2022-11-13T17:04:44.898113Z","shell.execute_reply.started":"2022-11-13T17:04:44.865081Z","shell.execute_reply":"2022-11-13T17:04:44.896954Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"A Game Of Thrones \nBook One of A Song of Ice and Fire \nBy George R. R. Martin \nPROLOGUE \n\"We should \n","output_type":"stream"}]},{"cell_type":"code","source":"def clean_text(text):\n    sample=text\n    sample=re.sub('[%s]'% re.escape(string.punctuation),'',sample)\n    sample=[word for word in sample.split() if word.isalpha()]\n    sample=[word.lower() for word in sample]\n    sample=' '.join(sample)\n    return sample","metadata":{"execution":{"iopub.status.busy":"2022-11-13T17:04:44.901583Z","iopub.execute_input":"2022-11-13T17:04:44.902241Z","iopub.status.idle":"2022-11-13T17:04:44.908711Z","shell.execute_reply.started":"2022-11-13T17:04:44.902202Z","shell.execute_reply":"2022-11-13T17:04:44.907433Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"cleaned_text=clean_text(text)\ncleaned_text[0:100]\nprint(len(cleaned_text.split()))","metadata":{"execution":{"iopub.status.busy":"2022-11-13T17:04:44.910076Z","iopub.execute_input":"2022-11-13T17:04:44.911122Z","iopub.status.idle":"2022-11-13T17:04:45.099509Z","shell.execute_reply.started":"2022-11-13T17:04:44.911087Z","shell.execute_reply":"2022-11-13T17:04:45.098246Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"292883\n","output_type":"stream"}]},{"cell_type":"code","source":"seq_doc=[]\nseq_len=50\nl=seq_len+1\ntokens=[w for w in cleaned_text.split()]\nfor i in range(l,len(tokens)):\n    seq=tokens[i-l:i]\n    line=' '.join(seq)\n    seq_doc.append(line)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-11-13T17:04:45.101508Z","iopub.execute_input":"2022-11-13T17:04:45.102384Z","iopub.status.idle":"2022-11-13T17:04:45.651231Z","shell.execute_reply.started":"2022-11-13T17:04:45.102338Z","shell.execute_reply":"2022-11-13T17:04:45.649968Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenizer=Tokenizer()\ntokenizer.fit_on_texts(seq_doc)\nsequences=tokenizer.texts_to_sequences(seq_doc)\nvocab_size=len(tokenizer.word_index)+1","metadata":{"execution":{"iopub.status.busy":"2022-11-13T17:04:45.652996Z","iopub.execute_input":"2022-11-13T17:04:45.653359Z","iopub.status.idle":"2022-11-13T17:05:08.470385Z","shell.execute_reply.started":"2022-11-13T17:04:45.653325Z","shell.execute_reply":"2022-11-13T17:05:08.469110Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"sequences=np.array(sequences)\nX,Y=sequences[:,:-1],sequences[:,-1]\nY=to_categorical(Y,num_classes=vocab_size)\nseq_len=X.shape[1]","metadata":{"execution":{"iopub.status.busy":"2022-11-13T17:05:08.471890Z","iopub.execute_input":"2022-11-13T17:05:08.472274Z","iopub.status.idle":"2022-11-13T17:05:11.165589Z","shell.execute_reply.started":"2022-11-13T17:05:08.472241Z","shell.execute_reply":"2022-11-13T17:05:11.164098Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(vocab_size,seq_len)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T17:05:11.167587Z","iopub.execute_input":"2022-11-13T17:05:11.168037Z","iopub.status.idle":"2022-11-13T17:05:11.174610Z","shell.execute_reply.started":"2022-11-13T17:05:11.167991Z","shell.execute_reply":"2022-11-13T17:05:11.173167Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"11924 50\n","output_type":"stream"}]},{"cell_type":"code","source":"def model(vocab_size,seq_length):\n    model=Sequential()\n    model.add(Embedding(vocab_size,50,input_length=seq_length))\n    model.add(LSTM(100,return_sequences=True))\n    model.add(LSTM(100))\n    model.add(Dense(100,activation='relu'))\n    model.add(Dense(vocab_size,activation='softmax'))\n    \n    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n    model.summary()\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-13T17:05:11.178348Z","iopub.execute_input":"2022-11-13T17:05:11.178712Z","iopub.status.idle":"2022-11-13T17:05:11.187459Z","shell.execute_reply.started":"2022-11-13T17:05:11.178675Z","shell.execute_reply":"2022-11-13T17:05:11.186126Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model=model(11924,50)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T17:05:11.188858Z","iopub.execute_input":"2022-11-13T17:05:11.189175Z","iopub.status.idle":"2022-11-13T17:05:11.868535Z","shell.execute_reply.started":"2022-11-13T17:05:11.189144Z","shell.execute_reply":"2022-11-13T17:05:11.867387Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"2022-11-13 17:05:11.232338: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 50, 50)            596200    \n_________________________________________________________________\nlstm (LSTM)                  (None, 50, 100)           60400     \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 100)               80400     \n_________________________________________________________________\ndense (Dense)                (None, 100)               10100     \n_________________________________________________________________\ndense_1 (Dense)              (None, 11924)             1204324   \n=================================================================\nTotal params: 1,951,424\nTrainable params: 1,951,424\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.fit(X,Y,batch_size=128,epochs=10)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T17:05:11.869991Z","iopub.execute_input":"2022-11-13T17:05:11.870860Z","iopub.status.idle":"2022-11-13T18:12:38.229187Z","shell.execute_reply.started":"2022-11-13T17:05:11.870822Z","shell.execute_reply":"2022-11-13T18:12:38.228301Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"2022-11-13 17:05:31.159699: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n2288/2288 [==============================] - 402s 174ms/step - loss: 6.4725 - accuracy: 0.0691\nEpoch 2/10\n2288/2288 [==============================] - 399s 174ms/step - loss: 5.9396 - accuracy: 0.0951\nEpoch 3/10\n2288/2288 [==============================] - 401s 175ms/step - loss: 5.6218 - accuracy: 0.1141\nEpoch 4/10\n2288/2288 [==============================] - 401s 175ms/step - loss: 5.4063 - accuracy: 0.1242\nEpoch 5/10\n2288/2288 [==============================] - 406s 177ms/step - loss: 5.2662 - accuracy: 0.1298\nEpoch 6/10\n2288/2288 [==============================] - 406s 178ms/step - loss: 5.1283 - accuracy: 0.1358\nEpoch 7/10\n2288/2288 [==============================] - 406s 177ms/step - loss: 5.0146 - accuracy: 0.1402\nEpoch 8/10\n2288/2288 [==============================] - 404s 176ms/step - loss: 4.9161 - accuracy: 0.1440\nEpoch 9/10\n2288/2288 [==============================] - 401s 175ms/step - loss: 4.8471 - accuracy: 0.1466\nEpoch 10/10\n2288/2288 [==============================] - 401s 175ms/step - loss: 4.7519 - accuracy: 0.1505\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f2a402ae410>"},"metadata":{}}]},{"cell_type":"code","source":"model.save('text_gen_model.h5')\njoblib.dump(tokenizer,open('tokenizer_text_gen.joblib','wb'))","metadata":{"execution":{"iopub.status.busy":"2022-11-13T18:12:38.230764Z","iopub.execute_input":"2022-11-13T18:12:38.231653Z","iopub.status.idle":"2022-11-13T18:12:38.663104Z","shell.execute_reply.started":"2022-11-13T18:12:38.231598Z","shell.execute_reply":"2022-11-13T18:12:38.662143Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def generate_seq(model,tokenizer,seq_length,seed_text,n_words):\n    result=list()\n    in_text=seed_text\n    for i in range(n_words):\n        encoded=tokenizer.texts_to_sequences([in_text])[0]\n        encoded=pad_sequences([encoded],maxlen=seq_length,truncating='pre')\n        y=model.predict(encoded,verbose=0)\n        ymax=np.argmax(y,axis=1)\n        out_word=''\n        for word,index in tokenizer.word_index.items():\n            if index==ymax:\n                out_word=word\n                break\n        in_text=in_text+' '+out_word\n        result.append(out_word)\n    return ' '.join(result)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T18:12:38.664375Z","iopub.execute_input":"2022-11-13T18:12:38.664910Z","iopub.status.idle":"2022-11-13T18:12:38.672166Z","shell.execute_reply.started":"2022-11-13T18:12:38.664879Z","shell.execute_reply":"2022-11-13T18:12:38.671205Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"seed_text=seq_doc[np.random.randint(0,len(seq_doc))]\nprint(seed_text+'\\n')\nprint(generate_seq(model,tokenizer,seq_len,seed_text,50))","metadata":{"execution":{"iopub.status.busy":"2022-11-13T18:12:38.673709Z","iopub.execute_input":"2022-11-13T18:12:38.674004Z","iopub.status.idle":"2022-11-13T18:12:43.007644Z","shell.execute_reply.started":"2022-11-13T18:12:38.673976Z","shell.execute_reply":"2022-11-13T18:12:43.006499Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"you back your homes or your crops nor can i restore your dead to life but perhaps i can give you some small measure of justice in the name of our king robert every eye in the hall was fixed on him waiting slowly ned struggled to his feet pushing himself\n\nthe paper and the wall was a man of the seven kingdoms and the sun had been a man in the wall and the sun of the wall and the sun of the world and the others were a man in the north the king had been a man in\n","output_type":"stream"}]}]}